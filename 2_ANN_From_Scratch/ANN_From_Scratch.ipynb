{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200e59ac",
   "metadata": {},
   "source": [
    "# Neural network for addition of 2 numbers\n",
    "### Mehdi ATTAOUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cafd9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a39d46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed6b4",
   "metadata": {},
   "source": [
    "## 1 . Prepare training and test data (typically loaded from file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771357d6",
   "metadata": {},
   "source": [
    "- Here we generate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f275a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeData = 20                             # Numbers from [-rangeData,+rangeData]\n",
    "lenData = 1000                             # How many pairs of numbers do we generate\n",
    "testProportion = 0.3                       # 30% testing, 70% training\n",
    "testEnd = round(lenData * testProportion)  # How many pairs of numbers are used for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b051c",
   "metadata": {},
   "source": [
    "- Generate 1000 pairs of numbers as 1000 seperate inputs for our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80c2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIn = np.random.randint(-rangeData, rangeData+1, size=(lenData, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea58ac4",
   "metadata": {},
   "source": [
    "- Generate the corresponding 1000 output values. These will be the sum of the two inputs.\n",
    "- We do not tell the network that it is the sum. The network shall learn this by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f203982",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOut = dataIn[:,0] + dataIn[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a0dfa",
   "metadata": {},
   "source": [
    "- Adding a '1' element to each input pair (related to bias - more on this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31f61df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIn = np.concatenate([np.ones([lenData,1]), dataIn], axis=1)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f800a",
   "metadata": {},
   "source": [
    "- The final data sets and 1 example each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3582142",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingIn   = dataIn[0:testEnd]\n",
    "testingOut  = dataOut[0:testEnd]\n",
    "trainingIn  = dataIn[testEnd:]\n",
    "trainingOut = dataOut[testEnd:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84ba63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  -5. -13.]\n",
      " [  1.  17.  -9.]\n",
      " [  1.   3.   7.]\n",
      " ...\n",
      " [  1.  -2.  15.]\n",
      " [  1. -11.  12.]\n",
      " [  1. -16.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print( trainingIn[:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c4320",
   "metadata": {},
   "source": [
    "## 2. Setting up neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b60f",
   "metadata": {},
   "source": [
    "![Addition_network.png](Addition_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e43ab7",
   "metadata": {},
   "source": [
    "Input layer length: 3 (1 bias + 2 numbers)\n",
    "\n",
    "Output layer length: 1 (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe58e5",
   "metadata": {},
   "source": [
    "### 2.1 Initialize weights: Numbers in the range from -2 to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281329",
   "metadata": {},
   "source": [
    "- We need a starting point for our weights. Let's select them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd2315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50183952  1.80285723  0.92797577]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "weights = np.random.uniform(-2, 2, size=(3,))\n",
    "weights = weights.astype(float)  \n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038dc2b",
   "metadata": {},
   "source": [
    "### 2.2 Activation function\n",
    "\n",
    "- Typically a monotonuous function that rescales a value to the range [0,1]\n",
    "- Here it is not necessary (Comes in the other examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cea533",
   "metadata": {},
   "source": [
    "### 2.3 Calculate output of our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35646410",
   "metadata": {},
   "source": [
    "The value of a neuron is given as the dot product of the two vectors: \n",
    "- weights \n",
    "- value of the neurons in the previous layer (including bias: value 1)\n",
    "\n",
    "$ y = w_0 + w_1x_1 + w_2x_2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e599e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [-0.50183952  1.80285723  0.92797577]\n",
      "\n",
      "\n",
      "[[  1.  -5. -13.]\n",
      " [  1.  17.  -9.]\n",
      " [  1.   3.   7.]\n",
      " ...\n",
      " [  1.  -2.  15.]\n",
      " [  1. -11.  12.]\n",
      " [  1. -16.  14.]]\n",
      "\n",
      "\n",
      "predicted output: \n",
      " \n",
      " [-2.15798106e+01  2.17949514e+01  1.14025625e+01 -1.74431531e+01\n",
      "  3.11808977e+01 -1.74431531e+01  2.69657733e+01  4.94749415e+01\n",
      "  6.60340076e+00 -1.10004170e+01 -9.72850289e+00  1.95419672e+01\n",
      " -1.93303659e+00 -3.03286252e+01 -2.56356521e+01 -4.49638603e+01\n",
      "  8.76263230e-01  2.57293184e+00  4.29732224e+00 -1.85304118e+01\n",
      "  1.22243497e+01  6.86887230e+00 -3.78898812e+00  4.14948198e+01\n",
      "  6.17864629e+00 -1.44214760e+01  8.40625799e+00 -2.00677975e+01\n",
      " -1.35719671e+01 -3.10973181e+01  4.31914884e+01 -3.05410024e+01\n",
      " -7.81945704e+00 -6.99766990e+00 -4.06956416e+01 -3.07002854e+01\n",
      " -1.89274445e+01  3.13932749e+01  2.13979187e+01 -7.23541965e+00\n",
      "  2.05761316e+01 -4.13050515e+01 -5.14065963e+01  2.40756574e+01\n",
      " -5.85731689e+00  3.52862940e+00 -6.99766990e+00 -4.40358845e+01\n",
      "  4.77251786e+01  3.87108925e+01  2.01513771e+01  1.01560209e+01\n",
      "  2.23789888e+01  4.12824425e+01 -6.61122451e-01  1.20119724e+01\n",
      " -2.19237490e+01 -4.13581458e+01 -1.79210019e+01 -8.64124419e+00\n",
      " -9.94088012e+00  9.01566790e+00 -4.21799329e+01 -1.66744602e+01\n",
      " -2.36367980e-01 -2.31702906e+01 -3.97145715e+01  1.79768597e+01\n",
      " -9.99397443e+00  2.62602615e+00  1.77391100e+01  1.74736384e+01\n",
      " -1.53494518e+01  5.85419169e-01  1.30101770e+00 -4.61042133e+01\n",
      " -1.07880398e+01 -1.20876757e+01  1.64394740e+01  1.40803012e+01\n",
      " -1.74962474e+01  9.65279961e+00 -3.07338959e+00  7.98150352e+00\n",
      " -1.09473227e+01 -1.03910071e+01 -8.48196127e+00  1.39741126e+01\n",
      " -1.03379128e+01 -3.01162480e+01 -2.61135008e+01 -3.10973181e+01\n",
      "  9.86517684e+00  1.91703070e+01  2.15572017e+01  1.91042762e+00\n",
      "  2.82376875e+01  3.28775663e+01  1.22243497e+01 -1.51370746e+01\n",
      "  1.40720632e+00 -4.13581458e+01 -1.43937542e+01  8.00922531e+00\n",
      "  1.33647027e+01 -6.30744388e+00  1.44519614e+01  1.44242396e+01\n",
      "  2.05761316e+01 -1.26970856e+01  2.20604230e+01 -1.44214760e+01\n",
      " -4.33202860e+01  6.44411783e+00  2.50036332e+01 -6.22897705e+00\n",
      " -2.36735119e+01  4.86000600e+01  2.93249462e+01  3.60709622e+00\n",
      " -3.56841026e+01  2.83840338e+00 -3.67182670e+01 -1.91929160e+01\n",
      "  1.25151937e+01 -2.05987406e+01 -1.92991046e+01 -4.32671916e+01\n",
      " -7.26314144e+00 -5.03552974e+00  2.02044714e+01 -3.52870699e+01\n",
      "  2.01661623e+00  4.49943456e+01 -4.61077527e+00 -3.16282611e+01\n",
      "  7.21281067e+00 -3.51808813e+01 -7.10385851e+00 -4.21799329e+01\n",
      "  1.61209082e+01 -2.08642121e+01  1.72081669e+01 -1.88489776e+01\n",
      " -2.40982664e+01  2.06823202e+01  3.30899435e+01  2.67912046e+00\n",
      " -2.24015978e+01 -1.00724413e+01 -3.73589381e+00  6.17864629e+00\n",
      "  3.46804235e+01  1.85733331e+00  2.91035639e-02  2.18480457e+01\n",
      "  2.87155362e+01  1.43457728e+01 -3.12035067e+01 -8.48196127e+00\n",
      " -2.74385093e+01  3.92566208e+00  2.16887628e+01  4.95811301e+01\n",
      " -2.91410666e+00  4.12824425e+01 -2.46397968e+00  2.48443503e+01\n",
      "  3.42244078e+00 -4.12519572e+01  5.13839873e+01  1.80299540e+01\n",
      " -4.42482617e+01 -3.78055257e+01 -3.89517674e+00  2.94842291e+01\n",
      "  3.75174451e+01  3.39648250e+01  4.12824425e+01  3.39117307e+01\n",
      "  5.35685914e+00 -1.63305219e+01 -3.51808813e+01 -9.19755980e+00\n",
      "  2.27229272e+01  3.14463692e+01 -6.61122451e-01  1.85733331e+00\n",
      " -2.19237490e+01 -3.95021943e+01 -2.91882722e+01  3.14463692e+01\n",
      "  3.11808977e+01 -4.53230845e+00 -1.15844544e+01 -2.70172943e+00\n",
      "  1.62270968e+01 -2.20830319e+01  1.60664698e-01  1.08864047e+00\n",
      "  3.09685205e+01  1.78452986e+01  2.54006659e+01  1.07654308e+01\n",
      " -1.44999429e+01 -1.74431531e+01  6.39102352e+00  7.42518791e+00\n",
      "  5.23119631e+01 -7.97873997e+00 -1.54556404e+01  2.83438761e+01\n",
      "  2.24320831e+01 -1.54556404e+01  2.81845932e+01 -1.16375487e+01\n",
      " -3.23438597e+01  2.70719619e+01  2.84500647e+01 -7.67311069e-01\n",
      "  1.25151937e+01 -2.85257680e+01  2.23789888e+01  6.60340076e+00\n",
      "  8.61863522e+00 -3.96614772e+01  1.60424414e+01  1.48489940e+01\n",
      "  1.50082770e+01 -1.34935003e+01 -8.64124419e+00  3.46273292e+01\n",
      "  7.79684807e+00  2.07607870e+01 -2.63512506e+01 -6.57291542e+00\n",
      "  1.24792339e+00  2.76813719e+01  2.13448244e+01  1.10839967e+01\n",
      "  3.18964962e+01 -2.44699265e+01 -3.07533797e+01  2.04699430e+01\n",
      "  1.43711453e+01 -4.86226690e+01  3.06245821e+01 -2.27455361e+01\n",
      " -3.05410024e+01  7.95613100e+00  2.29883987e+01  2.23258945e+01\n",
      " -1.83180345e+01 -4.24984988e+01 -3.01693423e+01 -8.95981005e+00\n",
      "  1.16403123e+01  2.76282776e+01 -1.18752985e+01  3.49458951e+01\n",
      " -1.58909822e+00  1.46897111e+01 -1.63028001e+01 -6.99766990e+00\n",
      "  1.47428054e+01 -3.59495741e+01 -1.46061315e+01  3.10387493e+00\n",
      " -5.96350551e+00  3.39648250e+01 -2.35419508e+01 -5.14065963e+01\n",
      " -1.15844544e+01 -5.14596906e+01 -5.24790698e+00 -1.71523090e+01\n",
      "  4.41194641e+01  4.58816630e+00  3.59269652e+01  4.08494500e+00\n",
      " -1.79210019e+01  1.75798270e+01  1.56176869e+01 -1.42090988e+01\n",
      " -4.50458665e+00 -3.10442237e+01  2.08138813e+01 -1.44745703e+01\n",
      "  1.59362527e+01  2.47912559e+01  1.90641184e+01 -3.03286252e+01\n",
      "  1.34177970e+01  5.13308930e+01  1.92234013e+01  3.20557792e+01\n",
      "  2.17949514e+01  4.03185069e+00  5.06601508e+00  3.60709622e+00\n",
      "  2.79468434e+01  1.45835225e+01 -3.59495741e+01 -3.07338959e+00\n",
      "  5.99399085e+00 -5.33156422e+01  3.11808977e+01  1.39210183e+01\n",
      " -8.98872203e-01 -4.61077527e+00  4.95811301e+01  3.68018466e+01\n",
      "  5.83470792e+00 -1.82118459e+01  2.56130431e+01  8.88410677e+00\n",
      "  4.35041655e+00 -1.74962474e+01 -4.58918360e+01 -4.50458665e+00\n",
      " -2.62727838e+01  2.43411290e+01  2.34131532e+01  8.03459782e+00\n",
      "  3.66956580e+01  4.22104183e+01 -1.85835061e+01  2.46319730e+01\n",
      " -2.86850509e+01 -6.73219835e+00 -1.61712390e+01  1.75267327e+01\n",
      " -5.85731689e+00  2.37039972e+01 -3.96083829e+01  3.92566208e+00\n",
      " -1.64219253e+00 -6.67910404e+00  4.01951838e+01  9.12185652e+00\n",
      " -2.25077864e+01 -5.85731689e+00  8.51244660e+00 -1.16906430e+01\n",
      " -1.86896947e+01 -3.68775499e+01 -2.20830319e+01  1.11370910e+01\n",
      "  2.58785146e+01  4.49412513e+01  1.07931526e+01 -1.42090988e+01\n",
      "  2.03106600e+01  3.68018466e+01 -1.81056573e+01  3.83923266e+01\n",
      "  1.98074387e+01 -2.70945709e+01  1.48489940e+01 -7.14216760e-01\n",
      "  5.22529801e+00 -2.71476652e+01  3.68018466e+01  8.30006937e+00\n",
      " -1.77086246e+01  2.95373234e+01  4.14417254e+01  2.13448244e+01\n",
      " -1.97238591e+01  1.94357786e+01  3.10216148e+01 -4.79070705e+01\n",
      " -9.79688304e-01 -4.77005820e+00 -3.39343397e+01  3.20557792e+01\n",
      " -4.21268386e+01 -2.77039808e+01 -1.08688559e+01 -1.87994228e+00\n",
      "  1.44242396e+01  3.47335178e+01 -2.59542179e+01  2.66472075e+01\n",
      " -4.15174287e+01 -2.48669592e+01  3.71328484e+00  2.75751832e+01\n",
      "  1.88517412e+01 -4.23923102e+01 -2.74916036e+01 -9.14446549e+00\n",
      "  1.06869640e+01 -9.62231427e+00 -1.17968317e+01  3.23212507e+01\n",
      "  2.27229272e+01 -4.42611983e+00 -3.76462427e+01  4.04075611e+01\n",
      "  2.91035639e-02 -2.64574392e+01  2.78530907e+00 -2.92413665e+01\n",
      "  1.45835225e+01 -2.77039808e+01  3.74643508e+01 -3.86273128e+01\n",
      "  2.57192317e+01  4.45660516e+00 -3.87865957e+01  5.72851930e+00\n",
      " -1.26970856e+01 -8.42886696e+00 -3.67713613e+01  9.91827115e+00\n",
      "  2.67533961e+01 -1.53217300e+01  4.05668440e+01  2.89149769e+00\n",
      "  7.21281067e+00  3.05078062e+00  8.11541392e+00  2.32538703e+01\n",
      "  2.81314989e+01  2.06292259e+01  2.60908919e+01 -4.05894530e+01\n",
      "  1.93826843e+01 -1.01255356e+01  3.24274393e+01  1.47428054e+01\n",
      "  8.90947928e+00 -2.05456462e+01  5.56923638e+00  1.43180510e+01\n",
      "  1.19057838e+01  2.88748192e+01  9.91827115e+00  2.95904177e+01\n",
      "  1.78983929e+01 -2.94006494e+01  2.73221476e+00 -1.77375366e+00\n",
      "  3.13932749e+01  6.55030645e+00  3.05714878e+01  1.48489940e+01\n",
      " -3.20783881e+01  3.32492265e+01 -2.55825578e+01 -1.60650503e+01\n",
      " -2.41088537e+00 -3.88927844e+01  5.94089654e+00 -1.24062416e+01\n",
      "  5.56923638e+00  3.95326796e+01 -2.97192153e+01  4.64126061e+00\n",
      "  7.21281067e+00 -1.11124944e+00 -1.66744602e+01  2.05761316e+01\n",
      "  3.03591105e+01 -3.48623154e+01  1.73143555e+01  5.22588688e+01\n",
      " -3.89517674e+00  4.64126061e+00  1.69805038e+00 -1.40498159e+01\n",
      " -7.97873997e+00 -6.38825998e+00 -1.21743806e+00  1.39210183e+01\n",
      "  5.33148662e+00 -1.62243333e+01 -1.89551663e+01 -5.15127849e+01\n",
      "  2.45788787e+01  3.59269652e+01  9.49351668e+00 -1.95114819e+01\n",
      " -1.59588617e+01 -1.74838114e+00  2.99768631e+00  1.85733331e+00\n",
      " -5.75112827e+00 -4.24454045e+01  1.67049456e+01 -3.38812454e+01\n",
      " -7.60707981e+00  9.22804514e+00 -2.94537438e+01  1.16149398e+01\n",
      " -6.36053819e+00 -1.63305219e+01 -7.15695282e+00 -2.59542179e+01\n",
      " -1.97769534e+01 -3.28576683e+00  1.29399482e+01  3.33023208e+01\n",
      "  1.00498323e+01  1.78452986e+01  4.87062487e+01 -3.32187411e+01\n",
      "  4.08494500e+00  3.18434019e+01 -6.51982112e+00 -1.59588617e+01\n",
      "  7.79684807e+00  8.83101246e+00 -2.70172943e+00  3.04652992e+01\n",
      " -2.36204176e+01  3.96919625e+01 -6.57291542e+00  1.37086410e+01\n",
      "  9.44042237e+00  1.43180510e+01  4.68502971e+01  2.94459200e+00\n",
      "  4.05668440e+01 -3.52339756e+01 -3.86804071e+01 -3.86804071e+01\n",
      "  4.12293482e+01  3.78891053e+01 -2.87912395e+01 -1.74431531e+01\n",
      " -1.52963575e+01 -1.94583875e+01 -2.52917137e+01 -2.66167221e+01\n",
      " -8.19111721e+00  2.90594746e+01 -2.13143391e+01 -1.48716030e+01\n",
      " -2.41513607e+01  4.85363784e+00  1.44773339e+01  2.41287517e+01\n",
      " -1.98300477e+01 -7.76636274e+00  1.61486300e+01  3.78891053e+01\n",
      " -2.64574392e+01 -7.34160827e+00  8.35316368e+00  8.14078644e+00\n",
      " -8.37577265e+00  8.77791815e+00  3.97875639e+00  1.25682880e+01\n",
      "  1.11901853e+01  1.51144656e+01  4.94749415e+01  3.68549409e+01\n",
      " -4.03239814e+01  3.68549409e+01 -1.08411341e+01 -3.34311184e+01\n",
      "  1.17211284e+01 -6.06969413e+00  3.41241079e+01 -3.55123837e+00\n",
      "  3.48928008e+01 -3.39195544e+00 -3.07533797e+01  1.34962638e+01\n",
      "  4.87062487e+01  3.58172371e+00  5.78161361e+00 -1.80525630e+01\n",
      " -3.12566010e+01  1.32054197e+01 -2.17644661e+01  1.34962638e+01\n",
      " -1.89274445e+01 -2.80791805e+00  1.23836326e+01 -2.87381452e+01\n",
      " -3.94491000e+01 -1.97238591e+01  3.71328484e+00 -8.37577265e+00\n",
      "  1.69957896e+01 -3.02755309e+01 -3.22907654e+01 -3.74869598e+01\n",
      "  2.69657733e+01  1.99920942e+01  3.48397065e+01 -2.52386194e+01\n",
      " -8.80052712e+00 -4.58918360e+01  2.74159003e+01  1.59362527e+01\n",
      " -2.35673233e+01 -1.26970856e+01 -1.82118459e+01 -2.14736220e+01\n",
      "  4.79230551e-01  2.66472075e+01  3.06245821e+01  1.93826843e+01\n",
      "  2.92187575e+01 -1.53600391e+00 -2.39389835e+01 -4.86226690e+01\n",
      "  2.41287517e+01  1.52991210e+01  1.33647027e+01 -3.19191052e+01\n",
      " -1.19814871e+01 -9.62231427e+00 -3.55123837e+00  2.54006659e+01\n",
      " -1.74838114e+00 -9.06599867e+00  2.57293184e+00  5.17220370e+00\n",
      " -1.60119560e+01 -1.07880398e+01  1.50082770e+01 -4.86757633e+01\n",
      " -1.10004170e+01  3.92672081e+01 -2.60604065e+01 -5.64493966e+00\n",
      "  2.62755473e+01 -1.90867274e+01  1.43711453e+01  2.82907818e+01\n",
      " -1.54810129e+01 -1.33342173e+01  3.74112565e+01 -1.33873116e+01\n",
      " -3.37750567e+01 -2.20299376e+01 -6.06969413e+00 -4.49107659e+01\n",
      " -3.13096953e+01 -2.35779106e+00  1.76329213e+01  3.13401806e+01\n",
      "  4.05137497e+01 -7.67311069e-01  1.26744767e+01 -2.33295735e+01\n",
      " -4.58918360e+01 -3.29532696e+01 -3.55123837e+00 -4.86757633e+01\n",
      "  1.95419672e+01  1.22243497e+01 -3.15751668e+01  3.77829167e+01\n",
      "  2.60065363e+00 -9.46303134e+00 -2.75446979e+01 -1.53600391e+00\n",
      " -7.60707981e+00  1.72612612e+01 -2.70945709e+01 -7.92564566e+00\n",
      " -5.54933833e-01  1.64394740e+01 -2.55825578e+01  2.04168487e+01\n",
      "  1.26744767e+01  4.40351086e+00  1.29399482e+01 -4.21799329e+01\n",
      " -2.65105335e+01  1.50613713e+01 -3.15220725e+01  7.31899929e+00\n",
      "  2.45257844e+01  4.53507199e+00  2.56130431e+01 -4.41420731e+01\n",
      " -4.39827902e+01  1.30101770e+00  7.79684807e+00 -1.74962474e+01\n",
      " -2.77039808e+01 -1.75493417e+01 -2.11550562e+01 -4.87624682e+00\n",
      "  2.51629161e+01 -2.83664851e+01  9.81208253e+00  2.17418571e+01\n",
      "  3.92566208e+00  9.81208253e+00 -9.19755980e+00 -1.63558944e+01]\n"
     ]
    }
   ],
   "source": [
    "y = weights[0]*trainingIn[:,0] + weights[1] * trainingIn[:,1] + weights[2] * trainingIn[:,2]\n",
    "\n",
    "print(\"weights:\",weights)\n",
    "print(\"\\n\")\n",
    "print(trainingIn)\n",
    "print(\"\\n\")\n",
    "print(\"predicted output: \\n \\n\",y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6479fed",
   "metadata": {},
   "source": [
    "- At the end of this notebook (after training our network) we will have the weights\n",
    "\n",
    "$ w_0 = 0, w_1 = 1, w_2 = 1 $\n",
    "\n",
    "because then our output will be \n",
    "\n",
    "$ y = x_1 + x_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e9159",
   "metadata": {},
   "source": [
    "### 2.4 Functions: Calculate accuracy and individual error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942ca8a",
   "metadata": {},
   "source": [
    "### - Accuracy: \n",
    "What is the rate at which the output is predicted correctly (only correct and wrong matter)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c6513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = np.sum(y == trainingOut)\n",
    "\n",
    "accuracy = correct_predictions / len(trainingOut)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237560c",
   "metadata": {},
   "source": [
    "- So far, output is random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6956b8",
   "metadata": {},
   "source": [
    "### - Error (better for learning): \n",
    "- For a pair of numbers we calculate:\n",
    "\n",
    "$ \\Delta = (y-Y)^2 $\n",
    "\n",
    "$ y $: Predicted result by the neural network\n",
    "\n",
    "$ Y $: Correct result (what we have calculated in the beginning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d28c01",
   "metadata": {},
   "source": [
    "- Here we only have a single output neuron but in general \n",
    "\n",
    "$ \\Delta = (\\vec{y}-\\vec{Y})^2=\\sum_j (y_j-Y_j)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01abd208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63438.90312454851\n"
     ]
    }
   ],
   "source": [
    "errors = y - trainingOut\n",
    "\n",
    "errors_squared = (y - trainingOut) ** 2\n",
    "\n",
    "total_error = np.sum(errors_squared)\n",
    "\n",
    "print(total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe2330e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f535da",
   "metadata": {},
   "source": [
    "### 2.5 Function: Calculate gradient (d Error / d weight)\n",
    "\n",
    "- All derivatives with respect to the individual weights (use chain rule)\n",
    "\n",
    "$ \\frac{\\partial }{\\partial w_i}\\Delta = 2(y-Y)\\cdot x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b675a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = np.zeros_like(weights) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64e7f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(weights.shape[0]):\n",
    "    gradients[i] = 2 * np.dot(errors, trainingIn[:, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab274fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients:  [  -197.64801479 156554.16797475 -15105.66179146]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradients: \", gradients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ebe73",
   "metadata": {},
   "source": [
    "## 3. Training: Use Gradient descent to change weights to minimize the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e85b48",
   "metadata": {},
   "source": [
    "Repeat the following process many time:\n",
    "- Select an input pair (index)\n",
    "- Calculate the gradient of the error \n",
    "- Change weights accoding to \n",
    "\n",
    "$ w_\\mathrm{new} = w_\\mathrm{old} - learingRate\\cdot gradient$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5295c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights: [-0.00929998  1.00002877  0.99998582]\n"
     ]
    }
   ],
   "source": [
    "iterations = 200000\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "     predictions = np.dot(trainingIn, weights)  \n",
    "\n",
    "     loss = mse_loss(trainingOut, predictions)\n",
    "\n",
    "     gradient = (2 / len(trainingIn)) * np.dot(trainingIn.T, (predictions - trainingOut))\n",
    "\n",
    "     gradient = gradient.flatten()\n",
    "\n",
    "     weights -= learning_rate * gradient\n",
    "\n",
    "\n",
    "print(f\"Trained Weights: {weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4889936",
   "metadata": {},
   "source": [
    "## 4. Application to test data set (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76b6de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights: [-0.00929998  1.00002877  0.99998582]\n",
      "Test Loss (MSE): 0.000087\n",
      "Accuracy: 0.93%\n"
     ]
    }
   ],
   "source": [
    "#lets test our model\n",
    "\n",
    "test_predictions = np.dot(testingIn, weights)\n",
    "\n",
    "test_loss = np.mean((testingOut - test_predictions) ** 2)\n",
    "\n",
    "correct_predictions = np.sum(np.abs(test_predictions - testingOut))\n",
    "\n",
    "accuracy = (correct_predictions / len(testingOut)) * 100\n",
    "\n",
    "print(f\"Trained Weights: {weights}\")\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
